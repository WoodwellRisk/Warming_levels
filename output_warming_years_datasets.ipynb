{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a63e89-3e63-420f-872a-fadf3ed1ef87",
   "metadata": {},
   "source": [
    "# Save warming year datasets\n",
    "\n",
    "#### Create datasets of warming amount (relative to 1850-1900) for every possible model, member, scenario combination available on Google Cloud, for each warming year identified via a warming level and temperature tolerance approach, and for each lat/lon point on a common grid. This results in one dataset per model/member/scenario combination. From these datasets, also create aggregated datasets that are the average across years and members (resulting in one file for each model and scenario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39664d3-f6bd-4d35-b1b7-f5afdcd29723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from warming_years import calc_warming_years_temperature_window, get_cmip6_data\n",
    "from warming_years import get_cmip6_data_at_warming_years\n",
    "from file_control import data_dir, gmst_table_dir, model_table_dir\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7008b1-c606-452d-b187-1b2447010d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_wl = 2\n",
    "temp_tol = 0.25\n",
    "cmip6_variable = 'tas' # only works for tas right now due to temporal averaging\n",
    "base_start = '1850-01'\n",
    "base_end = '1900-12'\n",
    "savedir = os.path.join(data_dir, 'zarr_' + str(target_wl) + 'C_warming_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25bc6a5-7e95-4565-b408-13595b1c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gmst table\n",
    "tab = pd.read_csv(os.path.join(gmst_table_dir, 'CMIP6_GMST_table_all.csv'))\n",
    "\n",
    "# create a df of unique model, member, and scenario combinations to loop over\n",
    "mms = tab[['model','member','scenario']].drop_duplicates()\n",
    "\n",
    "# remove historical cases since those will be handled in addition to each \n",
    "# scenario, not as a separate scenario\n",
    "mms = mms.loc[mms['scenario'] != 'historical']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f193c03-e0c7-4dad-862f-69fa121040ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new common grid to interpolate to\n",
    "newlats = np.arange(-90, 90.01, .5)\n",
    "newlons = np.arange(-180, 180, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a93ed7-a514-4aac-82bb-0e4b4b91e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mms.shape[0]):\n",
    "    print('running file ' + str(i+1) + ' of ' + str(mms.shape[0]), end = '\\r')\n",
    "    model = mms['model'].iloc[i]\n",
    "    member = mms['member'].iloc[i]\n",
    "    scenario = mms['scenario'].iloc[i]\n",
    "\n",
    "    wltable = calc_warming_years_temperature_window(mms.iloc[i:(i+1)], \n",
    "                                                    target_wl, \n",
    "                                                    temp_tol,\n",
    "                                                    3000).dropna()\n",
    "    \n",
    "    yrs = wltable['warming_year'].to_numpy()\n",
    "    \n",
    "    # if warming years are available for this model/member/scenario, then create\n",
    "    # dataset. Otherwise go to the next one.\n",
    "    if len(yrs) > 0:\n",
    "        # get base period data\n",
    "        base = get_cmip6_data(model, member, 'historical', cmip6_variable, \n",
    "                              base_start, base_end, None)\n",
    "        # aggregate to annual average\n",
    "        month_length = base.time.dt.days_in_month\n",
    "        weights = (month_length.groupby(\"time.year\") / month_length.groupby(\n",
    "            \"time.year\").sum())\n",
    "        base[cmip6_variable] = (base[cmip6_variable] * weights).groupby(\n",
    "            \"time.year\").sum(dim=\"time\").mean('year')\n",
    "        base = base.drop('time')\n",
    "        # get rid of nans\n",
    "        base[cmip6_variable] = base[cmip6_variable].interpolate_na(dim='lon')\n",
    "\n",
    "        # get warming year data\n",
    "        zz = get_cmip6_data_at_warming_years(model, member, scenario, \n",
    "                                             cmip6_variable, yrs, year_window=0,\n",
    "                                             outfilename=None)\n",
    "        # get rid of nans\n",
    "        zz[cmip6_variable] = zz[cmip6_variable].interpolate_na(dim='lon')\n",
    "                \n",
    "        # reset base lon and lat values so they are the same as the future \n",
    "        # dataset, so that we avoid horizontal bands of nans\n",
    "        base['lat'] = zz['lat']\n",
    "        base['lon'] = zz['lon']\n",
    "            \n",
    "        # calculate warming\n",
    "        # need to remove scenario info from base so that it's compatible with zz\n",
    "        zz['warming'] = zz[cmip6_variable] - base[cmip6_variable].isel(\n",
    "            scenario=0) \n",
    "\n",
    "        # interpolate to common spatial grid\n",
    "        zz = zz.interp(lon=newlons, lat=newlats, method=\"linear\")\n",
    "            \n",
    "        # clean up and prepare to concat\n",
    "        zz = zz.drop([cmip6_variable])\n",
    "           \n",
    "        # save the dataset\n",
    "        zz.to_netcdf(os.path.join(savedir, 'model_member_scenario_years',\n",
    "                                  model + '_' + member + '_' + scenario + '_' + \n",
    "                                  str(target_wl) + 'C_all_years.nc'))\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eceb07d-540e-4099-b9cc-37b121d9366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create aggregated files from those above that average across years, then \n",
    "# across members so that there is a file for each model and scenario\n",
    "\n",
    "# create warming years table and remove model/member/scenario combinations for \n",
    "# which warming years were not available because the the target warming level \n",
    "# was never reached\n",
    "wltable = calc_warming_years_temperature_window(mms, target_wl, temp_tol, 3000\n",
    "                                               ).dropna()\n",
    "\n",
    "# make table of all combinations of model and scenario that are available\n",
    "ms = wltable[['model','scenario']].drop_duplicates()\n",
    "\n",
    "# open table of first and last available years\n",
    "flyear = pd.read_csv(os.path.join(model_table_dir, \n",
    "                                  'all_zarr_models_first_last_year.csv'))\n",
    "\n",
    "for i in range(ms.shape[0]):    \n",
    "    m = ms['model'].iloc[i]\n",
    "    s = ms['scenario'].iloc[i]\n",
    "    print(m,s, end = '\\r')\n",
    "    xx = xr.open_mfdataset(os.path.join(savedir, 'model_member_scenario_years',\n",
    "                                        m + '_*' + s + '*.nc'))\n",
    "    \n",
    "    # remove any members that don't have data for the full 21st century (2015 \n",
    "    # through 2099)\n",
    "    thisflyear = flyear.loc[(flyear['model'] == m ) & \n",
    "                            (flyear['scenario'] == s) & \n",
    "                            (flyear['member'].isin(xx['member'].values))]\n",
    "    toremove = thisflyear.loc[(thisflyear['tas_first_year']>2015) | \n",
    "                              (thisflyear['tas_last_year']<2099)]['member']\n",
    "    \n",
    "    # if all members have incomplete timeseries, then don't save the dataset\n",
    "    if len(xx['member'].values) == len(toremove): \n",
    "        print(m + ' ' + s + \n",
    "              ' was not saved because all members had incomplete timeseries')\n",
    "    else:\n",
    "        xx = xx.drop_sel(member = toremove)  \n",
    "    \n",
    "        # pick only years <= 2100\n",
    "        xx = xx.where(xx.year <= 2100, drop=True)\n",
    "    \n",
    "        # aggregate across years and members\n",
    "        xm = xx.median('year').mean('member')\n",
    "    \n",
    "        # get rid of unnecesary variables\n",
    "        xm = xm.drop(['areacella'], errors='ignore')\n",
    "\n",
    "        # save the file\n",
    "        xm.to_netcdf(os.path.join(savedir, 'model_scenario', \n",
    "                                  m + '_' + s + '_' + str(target_wl) + 'C.nc'))\n",
    "        \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c5b23-5e7c-4148-ae0a-c705653e2a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "warming_levels-env",
   "language": "python",
   "name": "warming_levels-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
